#Data preprocessing


import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score


df=pd.read_csv('Heart.csv')
df.head()
df.shape
df.isnull().sum()
df.dtypes


df==0
df[df==0]
df[df==0].count()
df.columns
df['Age'].mean()
df.describe()
df.info()
df.nunique()


newdf=df[['age','sex','chestpain','RestBP','Chol']]
newdf
newdf.corr()


train,test = train_test_split(df,random_state=0,test_size=0.25)
train.shape
test.shape


from sklearn.metrics import ConfusionMatrixDisplay
actual=list(np.ones(45))+list(np.zeros(55))
predicted = list(np.ones(40))+list(np.zeroes(52))+list(np.ones(8))
ConfusionMatrixDisplay.from_prediction(actual,predicted)


print(classification_report(actual,predicted))
print(accuracy_score(actual,predicted))




#Regression
import pandas as pd
import matplot.pyplot as plt
import seaborn as sns


df=pd.read_csv('temperatures.csv')
df


x=df['YEAR']
y=df['ANNUAL']


plt.title('Temparature plot of India')
plt.xlabel('Year')
plt.ylabel('Annual avg Temp')
plt.scatter(x,y)




x.shape
x=x.values
x=x.reshape(117,1)
x.shape


from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(x,y)
regressor.coef_
regressor.intercept_
regressor.predict([[2035]])
predicted=regresoor.predict(x)
predicted


from sklearn.metrics import mean_absolute_error
mean_absolute_error(y,predicted)


from sklearn.metrics import mean_squared_error
mean_squared_error(y,predicted)


from sklearn.metrics import r2_score
r2_score(y,predicted)


plt.title('Temperature plot in India')
plt.xlabel('Year')
plt.ylabel('Annual avg temp')
plt.scatter(x,y,label='actual',color='r',marker='.')
plt.plot(x,predicted,label='predicted',color='g')
plt.legend()




sns.regplot(x='YEAR',y='ANNUAL',data=df)




Classification technique


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns


df=pd.read_csv("Admission_Predict.csv")


df.columns
df.shape
df.head()


from sklearn.preprocessing import Binarizer
df['Chance of Admit ']=[1 if each>0.75 else 0 for each in df['Chance of Admit ']]
df.head()


x=df.drop('Chance of Admit ',axis=1)
y=df['Chance of Admit ']
x
y


sns.countplot(x=y);
y.value_counts()


from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.25)


train.shape
test.shape




from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier(random_state=0)
classifier.fit(x_train,y_train)
y_pred = classifier.predict(x_test)
result=pd.DataFrame({'actual':y_test,'predicted':y_pred})




from sklearn.metrics import ConfusionMatrixDisplay,accuracy_score
from sklearn.metrics import classification_report


ConfusionMatrixDisplay.from_prediction(y_test,y_pred)
accuracy_score(y_test,y_pred)


print(classification_report(y_test,y_pred))


new=[[396,324,110,3,3.0,3.5,9.04,1]]
classifier.predict(new)[0]


from sklearn.tree import plot_tree
plt.figure(figsize=(12,12))
plot_tree(classifier,fontsize=8,filled=True,rounded=True,feature_names=x.columns)




#email


import numpy as np
import pandas as pd


df=pd.read_csv('spam -spam.csv , encoding ='ISO-8859-1')
df.head()
df['spam']=[1 if each =='spam' else 0 for each in df['v1']]


spam


newdf=df[['v1','v2','spam']]
newdf.head()
df.info()
df.describe()
df.dtypes


df.groupby('spam').describe()


from sklearn.model_selection import trian_test_split
x_train,x_test,y_train,y_test==train_test_split(df.v2,df.spam)


from sklearn.feature_extraction.text import CountVectorizer


v=CoutVectorizer()


x_train_count=v.fit_transform(x_train.values)
x_train_count.toarray()[:2]


from sklearn.naive_bayes import MultinominalNB
model=MultinominalNB()


model.fit(x_train_count,y_train)


emails=["registration","party"]
email_count=v.transform(emails)
model.predict(email_count)


x_test_count=v.transform(x_test)
model.score(x_test_count,y_test)




Clustering
import pandas as pd 
import matplotlib.pyplot as plt


df=pd.read_csv('mall_customer.csv')
df


x=df.iloc[:,3:]
x


plt.title('Unclustered Data')
plt.xlabel('Annual Income')
plt.ylabel('Spending Score')
plt.scatter(x['Annual Income (k$)']),x['Spending Score (1-100)'])


from sklearn.cluster import Kmeans,AgglomerativeClustering 
km=Kmeans(n_cluser=3)


x.shape


km.fit_predict(x)
km.inertia_


sse=[]
for k in range(1,16):
km = Kmeans(n_cluster=k)
km.fit_predict(x)
sse.append(km.inertia_)


sse


plt.title('Elbow Method')
plt.xlabel('Value of K')
plt.ylabel('SSE')
plt.grid()
plt.xticks(range(1,16))
plt.plot(range(1,16),sse,marker='.',color='blue')


from slearn.metrics import silhouette_score


silh = []
for k in range(2,16):
    km = KMeans(n_clusters=k)
    labels = km.fit_predict(x)
    score = silhouette_score(x, labels)
    silh.append(score)


silh






plt.title('silh Method')
plt.xlabel('Value of K')
plt.ylabel('silh score')
plt.grid()
plt.xticks(range(2,16))
plt.bar(range(2,16), silh, color='blue')


 km =KMeans(n_cluster=5)
labels=km.fit_predict(x)


labels


km.cluster_center_
cent=lm.cluster_centers_


plt.figure(figsize=(16,9))


plt.subplot(1,2,1)
plt.title('Unclustered Data')
plt.xlabel('Annual Income')
plt.ylabel('Spending Score')
plt.scatter(x['Annual Income (k$)'], x[ 'Spending Score (1-100)'])


plt.subplot(1,2,2)
plt.title('Clustered Data')
plt.xlabel('Annual Income')
plt.ylabel('Spending Score')
plt.scatter (x['Annual Income (k$)'], x['Spending Score (1-100)'], c=labels)
plt.scatter (cent[:,0], cent[:,1], s=100, color='k')


km.inertia_
df[labels==4]
km.predict([[46,78]])






#lab6 Association learning
Ipip install mlxtend
import csv
import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import aprilori, assoclation_rules
dataset = []
with open(“"Market_Basket_Optimisation.csv") as file:
reader = csv.reader(file, delimiter=",")
for row in reader:
dataset.append(row)
dataset


te = TransactionEncoder()
df=te.fit_transform(dataset)


df = pd.DataFrame(df, columns=te.columns_)
df


item_set = apriori(df, min_support=0.01, use_colnames=True)
item_set


rules = association_rules(item set, metric="confidence", min_threshold=0.25)
print(f" Confidence Level : 25%, No of rules : {len(rules)}")
rules


rules = assoclation_rules(item_set, metric="confidence", min_threshold=0.20)
print(f" Confidence Level : 20%, No of rules : {len(rules)}")
rules


rules = rules[["antecedents", "consequents", "support", "confidence"]]


rules